{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be2df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994de026-f4d4-4867-9da3-4f5710b2f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import networkx as nx  \n",
    "import ast  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV, GroupShuffleSplit  \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c84d849-8f20-4e2b-b63f-0a68281f1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data\n",
    "df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02caca81-f64f-4ae3-a41e-06feced9ced7",
   "metadata": {},
   "source": [
    "## Inspect the Data\n",
    "\n",
    "We inspect the train dataset to check the structure of the data and understand the dataset more. We check the summary statistics and look out for possible errors, missing values, outliers or duplicates. We also check the the datatypes of each variable and ensure they are of the proper type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9f5e0f-58fd-468b-925a-7b2099094ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "      <th>n</th>\n",
       "      <th>edgelist</th>\n",
       "      <th>root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>[(6, 4), (2, 6), (2, 23), (20, 2), (15, 20), (...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>[(8, 9), (14, 8), (4, 14), (5, 4), (1, 2), (6,...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>[(2, 10), (2, 14), (4, 2), (16, 4), (6, 16), (...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>[(30, 1), (14, 24), (21, 14), (3, 21), (7, 3),...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>[(19, 13), (16, 19), (2, 16), (4, 10), (4, 15)...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language  sentence   n                                           edgelist  \\\n",
       "0  Japanese         2  23  [(6, 4), (2, 6), (2, 23), (20, 2), (15, 20), (...   \n",
       "1  Japanese         5  18  [(8, 9), (14, 8), (4, 14), (5, 4), (1, 2), (6,...   \n",
       "2  Japanese         8  33  [(2, 10), (2, 14), (4, 2), (16, 4), (6, 16), (...   \n",
       "3  Japanese        11  30  [(30, 1), (14, 24), (21, 14), (3, 21), (7, 3),...   \n",
       "4  Japanese        12  19  [(19, 13), (16, 19), (2, 16), (4, 10), (4, 15)...   \n",
       "\n",
       "   root  \n",
       "0    10  \n",
       "1    10  \n",
       "2     3  \n",
       "3    30  \n",
       "4    11  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6652e96-5255-4f8d-8648-16c0ddee57fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10500, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f6e49-2ac0-472d-9bde-d3c11a3ef691",
   "metadata": {},
   "source": [
    "Target variable: root. \n",
    "It says the node that is the root. But to make the task simpler, we will turn it to a binary classification task. Such that, each row takes a node and the target variable will the is_root, where 0 will indicate that the node isn't the root and 1 indicates that it is the root.\n",
    "\n",
    "This will cause data imbalance in the dataset because most of the classes will be 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dfd3053-f824-4e53-9f8b-127823da14b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['language', 'sentence', 'n', 'edgelist', 'root'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check other variables in the data\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ea32e6-01ea-4e01-a7a2-3ef2dfa911bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10500 entries, 0 to 10499\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   language  10500 non-null  object\n",
      " 1   sentence  10500 non-null  int64 \n",
      " 2   n         10500 non-null  int64 \n",
      " 3   edgelist  10500 non-null  object\n",
      " 4   root      10500 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 410.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Basic info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c3e269-6e77-47aa-93a6-84a09b92c0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language    0\n",
       "sentence    0\n",
       "n           0\n",
       "edgelist    0\n",
       "root        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5401a79c-6a95-4f68-abbe-0b1fd138047a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c070f10-463f-4d26-9ea5-e9db86188c2a",
   "metadata": {},
   "source": [
    "Training data contains no missing values or duplicated columns, which is good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54658308-9c5a-46cf-b3c9-c92671c74426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language    object\n",
       "sentence     int64\n",
       "n            int64\n",
       "edgelist    object\n",
       "root         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc932cd6-32fc-4cce-9c55-c991c5c5dd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the type of object\n",
    "type(df['edgelist'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabb6bb8-3d7a-4cba-9ed3-715a9fc833a7",
   "metadata": {},
   "source": [
    "Edgelist is of the datatype object (string).\n",
    "\n",
    "It needs to be converted to a python edgelist which can be used to create the networkx tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eff9fbc5-6c19-49e0-85f0-02d296be9a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>n</th>\n",
       "      <th>root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>494.778000</td>\n",
       "      <td>18.807524</td>\n",
       "      <td>9.844476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>290.256632</td>\n",
       "      <td>8.190593</td>\n",
       "      <td>7.207740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>233.500000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>483.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>742.250000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>995.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentence             n          root\n",
       "count  10500.000000  10500.000000  10500.000000\n",
       "mean     494.778000     18.807524      9.844476\n",
       "std      290.256632      8.190593      7.207740\n",
       "min        2.000000      3.000000      1.000000\n",
       "25%      233.500000     13.000000      4.000000\n",
       "50%      483.000000     18.000000      8.000000\n",
       "75%      742.250000     23.000000     14.000000\n",
       "max      995.000000     70.000000     68.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9813e827-32e4-4f13-ac0f-04fff59fc0bf",
   "metadata": {},
   "source": [
    "There are sentences with 3 nodes (words) and some with as many as 70 nodes. This should be taken into consideration when normalizing. it will be advisable to normalize per sentence coz of this imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1395f243-9bce-41b8-be4e-72cb3236d964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sentence length distribution\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(data=df, x='n', bins=30, kde=True)\n",
    "plt.title('Distribution of Tree Sizes (Number of Nodes)')\n",
    "plt.xlabel('Number of nodes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f679966a-2f4e-4e26-8d68-e0ad371ef12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21 languages. Each language has the following number of sentences:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language\n",
       "Japanese      500\n",
       "German        500\n",
       "Arabic        500\n",
       "Portuguese    500\n",
       "Chinese       500\n",
       "Czech         500\n",
       "Turkish       500\n",
       "Thai          500\n",
       "Polish        500\n",
       "Korean        500\n",
       "Icelandic     500\n",
       "Finnish       500\n",
       "Spanish       500\n",
       "Swedish       500\n",
       "Indonesian    500\n",
       "Italian       500\n",
       "French        500\n",
       "Hindi         500\n",
       "English       500\n",
       "Galician      500\n",
       "Russian       500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Language distribution (check number of languages and number of sentences per language)\n",
    "lang = df['language'].nunique()\n",
    "print(f'There are {lang} languages. Each language has the following number of sentences:')\n",
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54f84117-67b9-4b91-a3df-3ac611e5b289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10500.000000\n",
      "mean         9.844476\n",
      "std          7.207740\n",
      "min          1.000000\n",
      "25%          4.000000\n",
      "50%          8.000000\n",
      "75%         14.000000\n",
      "max         68.000000\n",
      "Name: root, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Root node analysis\n",
    "print(df['root'].describe())\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(data=df, x='root', bins=30)\n",
    "plt.title('Distribution of Root Nodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd71c310-9662-4b09-b6dc-abbacc33c2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_tree(edges, root, title=\"\"):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    pos = nx.planar_layout(G) if nx.is_planar(G) else nx.spring_layout(G)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    nx.draw(G, pos, with_labels=True, arrows=True, node_size=800, node_color='lightblue')\n",
    "    plt.title(f\"Tree Visualization (Root: {root}) {title}\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize first tree\n",
    "for i, row in df.head(1).iterrows():\n",
    "    visualize_tree(ast.literal_eval(row['edgelist']), row['root'], f\"Language: {row['language']}, Sentence: {row['sentence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4caa07b-981d-4a77-a75c-a5f463098582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " visualize_tree(ast.literal_eval(df.iloc[389]['edgelist']), df.iloc[389]['root'], f\"Language: {df.iloc[389]['language']}, Sentence: {df.iloc[389]['sentence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f42c1fb0-3cfd-4eb2-aea7-f21911c6cd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " visualize_tree(ast.literal_eval(df.iloc[10098]['edgelist']), df.iloc[10098]['root'], f\"Language: {df.iloc[10098]['language']}, Sentence: {df.iloc[10098]['sentence']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839fc29",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe7e43-7a6c-4c54-b094-7c12d6df55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(df):\n",
    "    \"\"\"\n",
    "    Enhanced preprocessing with additional features for tree root prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    df['edgelist'] = df['edgelist'].apply(ast.literal_eval)\n",
    "    \n",
    "    def enhanced_features(edgelist):\n",
    "        \"\"\"\n",
    "        Extract features for tree root prediction\n",
    "        \"\"\"\n",
    "        T = nx.from_edgelist(edgelist)\n",
    "        \n",
    "        # Basic centrality measures (your existing ones)\n",
    "        dc = nx.degree_centrality(T)\n",
    "        cc = nx.harmonic_centrality(T)\n",
    "        bc = nx.betweenness_centrality(T)\n",
    "        pc = nx.pagerank(T)\n",
    "        clc = nx.closeness_centrality(T)\n",
    "        kz = nx.katz_centrality_numpy(T, alpha=0.005, beta=1.0)\n",
    "        lc = nx.load_centrality(T)\n",
    "        andc = nx.average_neighbor_degree(T)\n",
    "        ec = nx.eigenvector_centrality_numpy(T)\n",
    "        \n",
    "        # NEW FEATURES FOR ROOT PREDICTION\n",
    "        \n",
    "        \n",
    "        # 2. Distance-based features\n",
    "        # Average distance to all other nodes\n",
    "        shortest_paths = dict(nx.all_pairs_shortest_path_length(T))\n",
    "        sum_distances = {}\n",
    "        \n",
    "        for node in T.nodes():\n",
    "            distances = list(shortest_paths[node].values())\n",
    "            sum_distances[node] = sum(distances)\n",
    "        \n",
    "        # 3. Tree-specific features\n",
    "        # Distance from center(s) of the tree\n",
    "        periphery_nodes = nx.periphery(T)\n",
    "        \n",
    "        distance_from_periphery = {}\n",
    "       \n",
    "        for node in T.nodes():\n",
    "            # Distance to closest periphery\n",
    "            distance_from_periphery[node] = min(nx.shortest_path_length(T, node, periph) \n",
    "                                              for periph in periphery_nodes)\n",
    "      \n",
    "        # 4. Subtree size features\n",
    "        # For each node, compute size of subtree when that node is removed\n",
    "        subtree_sizes = {}\n",
    "        for node in T.nodes():\n",
    "            T_copy = T.copy()\n",
    "            T_copy.remove_node(node)\n",
    "            components = list(nx.connected_components(T_copy))\n",
    "            # Size of largest component when node is removed\n",
    "            subtree_sizes[node] = max(len(comp) for comp in components) if components else 0\n",
    "        \n",
    "        # 5. Neighbor-based features\n",
    "        neighbor_degrees = {}\n",
    "        neighbor_centralities = {}\n",
    "        second_order_neighbors = {}\n",
    "        \n",
    "        for node in T.nodes():\n",
    "            neighbors = list(T.neighbors(node))\n",
    "            if neighbors:\n",
    "                neighbor_degrees[node] = np.mean([T.degree(n) for n in neighbors])\n",
    "                neighbor_centralities[node] = np.mean([dc[n] for n in neighbors])\n",
    "                # Second-order neighbors (neighbors of neighbors)\n",
    "                second_neighbors = set()\n",
    "                for neighbor in neighbors:\n",
    "                    second_neighbors.update(T.neighbors(neighbor))\n",
    "                second_neighbors.discard(node)  # Remove self\n",
    "                second_order_neighbors[node] = len(second_neighbors)\n",
    "            else:\n",
    "                neighbor_degrees[node] = 0\n",
    "                neighbor_centralities[node] = 0\n",
    "                second_order_neighbors[node] = 0\n",
    "        \n",
    "        \n",
    "        # 7. Relative position features\n",
    "        # Node's centrality relative to max centrality\n",
    "        max_dc = max(dc.values())\n",
    "        relative_centrality = {node: dc[node] / max_dc for node in T.nodes()}\n",
    "        \n",
    "        # 8. Tree depth features (if we can infer a root)\n",
    "        # Use the most central node as a proxy root for depth calculation\n",
    "        proxy_root = max(dc.keys(), key=lambda x: dc[x])\n",
    "        depths_from_proxy = nx.single_source_shortest_path_length(T, proxy_root)\n",
    "        \n",
    "        # 9. Bridge and articulation point features\n",
    "        bridges = list(nx.bridges(T))\n",
    "        bridge_count = {node: sum(1 for bridge in bridges if node in bridge) for node in T.nodes()}\n",
    "        \n",
    "        # 10. Statistical features within neighborhoods\n",
    "        local_degree_variance = {}\n",
    "        \n",
    "        for node in T.nodes():\n",
    "            neighbors = list(T.neighbors(node))\n",
    "            if len(neighbors) > 1:\n",
    "                neighbor_degrees_list = [T.degree(n) for n in neighbors]\n",
    "                local_degree_variance[node] = np.var(neighbor_degrees_list)\n",
    "            else:\n",
    "                local_degree_variance[node] = 0\n",
    "\n",
    "        # A. Distance-based variants\n",
    "        median_distances = {}\n",
    "        distance_std = {}\n",
    "        distance_range = {}\n",
    "        \n",
    "        for node in T.nodes():\n",
    "            distances = list(shortest_paths[node].values())\n",
    "            median_distances[node] = np.median(distances)\n",
    "            distance_std[node] = np.std(distances)\n",
    "            distance_range[node] = max(distances) - min(distances)\n",
    "        \n",
    "        # B. Tree balance measures\n",
    "        subtree_balance = {}\n",
    "        subtree_count = {}\n",
    "        max_subtree_ratio = {}\n",
    "        \n",
    "        for node in T.nodes():\n",
    "            T_copy = T.copy()\n",
    "            T_copy.remove_node(node)\n",
    "            components = list(nx.connected_components(T_copy))\n",
    "            component_sizes = [len(comp) for comp in components]\n",
    "            \n",
    "            subtree_count[node] = len(components)\n",
    "            if component_sizes:\n",
    "                max_subtree_ratio[node] = max(component_sizes) / len(T.nodes())\n",
    "                # Balance measure: how evenly distributed are the subtrees\n",
    "                if len(component_sizes) > 1:\n",
    "                    subtree_balance[node] = 1 - (np.std(component_sizes) / np.mean(component_sizes))\n",
    "                else:\n",
    "                    subtree_balance[node] = 1\n",
    "            else:\n",
    "                max_subtree_ratio[node] = 0\n",
    "                subtree_balance[node] = 1\n",
    "        \n",
    "        # C. Neighborhood depth and reach\n",
    "        two_hop_size = {}\n",
    "        three_hop_size = {}\n",
    "        neighborhood_efficiency = {}\n",
    "        reach_ratio = {}\n",
    "        \n",
    "        for node in T.nodes():\n",
    "            # Two-hop neighborhood\n",
    "            two_hop = set()\n",
    "            for path_length in [1, 2]:\n",
    "                two_hop.update(nx.single_source_shortest_path_length(T, node, cutoff=path_length).keys())\n",
    "            two_hop_size[node] = len(two_hop)\n",
    "            \n",
    "            # Three-hop neighborhood\n",
    "            three_hop = set()\n",
    "            for path_length in [1, 2, 3]:\n",
    "                three_hop.update(nx.single_source_shortest_path_length(T, node, cutoff=path_length).keys())\n",
    "            three_hop_size[node] = len(three_hop)\n",
    "            \n",
    "            # Neighborhood efficiency (how quickly we reach nodes)\n",
    "            total_nodes = len(T.nodes())\n",
    "            if total_nodes > 1:\n",
    "                neighborhood_efficiency[node] = three_hop_size[node] / total_nodes\n",
    "                reach_ratio[node] = two_hop_size[node] / total_nodes\n",
    "            else:\n",
    "                neighborhood_efficiency[node] = 1\n",
    "                reach_ratio[node] = 1\n",
    "        \n",
    "        # D. Centrality combinations and ratios\n",
    "        centrality_product = {}\n",
    "        centrality_ratio_1 = {}\n",
    "        centrality_ratio_2 = {}\n",
    "        centrality_sum = {}\n",
    "        \n",
    "        for node in T.nodes():\n",
    "            # Product of key centralities\n",
    "            centrality_product[node] = dc[node] * bc[node] * cc[node]\n",
    "            # Sum of key centralities\n",
    "            centrality_sum[node] = dc[node] + bc[node] + cc[node]\n",
    "            # Ratios between different centralities\n",
    "            centrality_ratio_1[node] = bc[node] / dc[node] if dc[node] > 0 else 0\n",
    "            centrality_ratio_2[node] = cc[node] / pc[node] if pc[node] > 0 else 0\n",
    "        \n",
    "        # E. Advanced tree properties\n",
    "        # Node vulnerability (how much connectivity is lost if node removed)\n",
    "        edge_connectivity_impact = {}\n",
    "        \n",
    "        for node in T.nodes():\n",
    "            T_copy = T.copy()\n",
    "            T_copy.remove_node(node)\n",
    "            if T_copy.number_of_nodes() > 1:\n",
    "                # Measure fragmentation\n",
    "                components = list(nx.connected_components(T_copy))\n",
    "                edge_connectivity_impact[node] = T.number_of_edges() - T_copy.number_of_edges()\n",
    "            else:\n",
    "                edge_connectivity_impact[node] = T.number_of_edges()\n",
    "        \n",
    "        # F. Degree-based and flow features\n",
    "        degree_dominance = {}\n",
    "        flow_concentration = {}\n",
    "        \n",
    "        for node in T.nodes():\n",
    "            neighbors = list(T.neighbors(node))\n",
    "            node_degree = T.degree(node)\n",
    "            \n",
    "            # How much this node's degree dominates its neighborhood\n",
    "            if neighbors:\n",
    "                total_neighbor_degree = sum(T.degree(n) for n in neighbors)\n",
    "                degree_dominance[node] = node_degree / (node_degree + total_neighbor_degree)\n",
    "                \n",
    "                # Flow concentration - how much betweenness flows through this vs neighbors\n",
    "                total_neighbor_betweenness = sum(bc[n] for n in neighbors)\n",
    "                flow_concentration[node] = bc[node] / (bc[node] + total_neighbor_betweenness) if (bc[node] + total_neighbor_betweenness) > 0 else 0\n",
    "            else:\n",
    "                degree_dominance[node] = 1\n",
    "                flow_concentration[node] = 1\n",
    "        \n",
    "        # Combine all features\n",
    "        features = {}\n",
    "        for node in T.nodes():\n",
    "            features[node] = (\n",
    "                # Original centrality features\n",
    "                dc[node], bc[node], clc[node], \n",
    "                kz[node], ec[node],\n",
    "                \n",
    "                # New features\n",
    "                sum_distances[node],               # 6: Sum of distances\n",
    "                distance_from_periphery[node],     # 7: Distance from periphery\n",
    "                subtree_sizes[node],               # 8: Size of largest subtree when removed\n",
    "                neighbor_degrees[node],            # 9: Average neighbor degree\n",
    "                neighbor_centralities[node],       # 10: Average neighbor centrality\n",
    "                second_order_neighbors[node],      # 11: Number of second-order neighbors\n",
    "                relative_centrality[node],         # 12: Relative centrality\n",
    "                depths_from_proxy[node],           # 13: Depth from proxy root\n",
    "                bridge_count[node],                # 14: Number of bridges connected to\n",
    "                local_degree_variance[node],       # 15: Local degree variance\n",
    "                median_distances[node],            # 16: Median distance to all nodes\n",
    "                distance_std[node],                # 17: Standard deviation of distances\n",
    "                distance_range[node],              # 18: Range of distances (max - min)\n",
    "                subtree_balance[node],             # 19: How balanced subtrees are\n",
    "                subtree_count[node],               # 20: Number of subtrees when removed\n",
    "                two_hop_size[node],                # 21: Size of 2-hop neighborhood\n",
    "                three_hop_size[node],              # 22: Size of 3-hop neighborhood\n",
    "                neighborhood_efficiency[node],     # 23: 3-hop reach efficiency\n",
    "                reach_ratio[node],                 # 24: 2-hop reach ratio\n",
    "                centrality_product[node],          # 25: Product of key centralities\n",
    "                centrality_sum[node],              # 26: Sum of key centralities  \n",
    "                centrality_ratio_1[node],          # 27: Betweenness/Degree ratio\n",
    "                centrality_ratio_2[node],          # 28: Harmonic/PageRank ratio\n",
    "                edge_connectivity_impact[node],    # 29: Edge loss impact\n",
    "                flow_concentration[node],          # 30: Betweenness concentration\n",
    "            )\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    df['centralities'] = df['edgelist'].apply(enhanced_features)\n",
    "    \n",
    "    def binary_classification(df):\n",
    "        \"\"\"\n",
    "        Convert to binary classification format with enhanced features\n",
    "        \"\"\"\n",
    "        records = []\n",
    "        has_root = 'root' in df.columns\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            for vertex, feature_tuple in row['centralities'].items():\n",
    "                record = {\n",
    "                    'language': row['language'],\n",
    "                    'sentence': row['sentence'],\n",
    "                    'n': row['n'],\n",
    "                    'vertex': vertex,\n",
    "                }\n",
    "                \n",
    "                # Add all features with descriptive names\n",
    "                feature_names = [\n",
    "                    'degree', 'betweenness',\n",
    "                    'katz', 'eigenvector', 'sum_distance',\n",
    "                    'distance_from_periphery', \n",
    "                    'subtree_size',\n",
    "                    'neighbor_degrees', 'neighbor_centralities', 'second_order_neighbors',\n",
    "                     'relative_centrality',\n",
    "                    'depth_from_proxy', 'bridge_count',\n",
    "                    'local_degree_variance',\n",
    "                    'median_distance',             # Median distance to all nodes\n",
    "                    'distance_std',                # Std dev of distances\n",
    "                    'distance_range',              # Range of distances (max-min)\n",
    "                    'subtree_balance',             # Balance of subtrees when removed\n",
    "                    'subtree_count',               # Number of components when removed\n",
    "                    'two_hop_size',                # Nodes within 2 hops\n",
    "                    'three_hop_size',              # Nodes within 3 hops\n",
    "                    'reach_ratio',                 # 2-hop reach efficiency\n",
    "                    'centrality_product',          # Product of centralities\n",
    "                    'centrality_sum',              # Sum of centralities\n",
    "                    'centrality_ratio_1',          # Betweenness/Degree ratio\n",
    "                    'centrality_ratio_2',          # Harmonic/PageRank ratio\n",
    "                    'edge_connectivity_impact',    # Edge loss when removed\n",
    "                    'flow_concentration'           # Betweenness flow concentration        \n",
    "                ]\n",
    "                \n",
    "                for i, feature_name in enumerate(feature_names):\n",
    "                    record[feature_name] = feature_tuple[i]\n",
    "                \n",
    "                if has_root:\n",
    "                    record['root'] = row['root']\n",
    "                records.append(record)\n",
    "        \n",
    "        binary_df = pd.DataFrame(records)\n",
    "        binary_df = binary_df.sort_values(['language', 'sentence', 'vertex']).reset_index(drop=True)\n",
    "        \n",
    "        if has_root:\n",
    "            binary_df['is_root'] = (binary_df['vertex'] == binary_df['root']).astype(int)\n",
    "        \n",
    "        return binary_df\n",
    "    \n",
    "    return binary_classification(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0f7b847-4d30-40e1-bdd9-a32897be0cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "      <th>n</th>\n",
       "      <th>vertex</th>\n",
       "      <th>degree</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>katz</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>sum_distance</th>\n",
       "      <th>distance_from_periphery</th>\n",
       "      <th>...</th>\n",
       "      <th>three_hop_size</th>\n",
       "      <th>reach_ratio</th>\n",
       "      <th>centrality_product</th>\n",
       "      <th>centrality_sum</th>\n",
       "      <th>centrality_ratio_1</th>\n",
       "      <th>centrality_ratio_2</th>\n",
       "      <th>edge_connectivity_impact</th>\n",
       "      <th>flow_concentration</th>\n",
       "      <th>root</th>\n",
       "      <th>is_root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.314969</td>\n",
       "      <td>0.270862</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.061111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>67.425966</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.316552</td>\n",
       "      <td>0.368517</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>5.722222</td>\n",
       "      <td>2.2500</td>\n",
       "      <td>47.706939</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.314969</td>\n",
       "      <td>0.270862</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.061111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>67.425966</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.314961</td>\n",
       "      <td>0.200846</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.727778</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>59.327327</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.318118</td>\n",
       "      <td>0.450105</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.733796</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>32.569364</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.314961</td>\n",
       "      <td>0.200846</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.727778</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>59.327327</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.316536</td>\n",
       "      <td>0.218849</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>1.7500</td>\n",
       "      <td>41.374339</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.316528</td>\n",
       "      <td>0.121933</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.196708</td>\n",
       "      <td>4.427778</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>34.395413</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.314953</td>\n",
       "      <td>0.054409</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.127778</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>46.973874</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.319693</td>\n",
       "      <td>0.607014</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.027778</td>\n",
       "      <td>7.277778</td>\n",
       "      <td>1.6875</td>\n",
       "      <td>29.661141</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    language  sentence   n  vertex    degree  betweenness      katz  \\\n",
       "588   Arabic        62  10       1  0.111111     0.000000  0.360000   \n",
       "589   Arabic        62  10       2  0.222222     0.500000  0.473684   \n",
       "590   Arabic        62  10       3  0.111111     0.000000  0.360000   \n",
       "591   Arabic        62  10       4  0.111111     0.000000  0.310345   \n",
       "592   Arabic        62  10       5  0.333333     0.416667  0.428571   \n",
       "593   Arabic        62  10       6  0.111111     0.000000  0.310345   \n",
       "594   Arabic        62  10       7  0.222222     0.388889  0.391304   \n",
       "595   Arabic        62  10       8  0.222222     0.222222  0.310345   \n",
       "596   Arabic        62  10       9  0.111111     0.000000  0.243243   \n",
       "597   Arabic        62  10      10  0.444444     0.750000  0.529412   \n",
       "\n",
       "     eigenvector  sum_distance  distance_from_periphery  ...  three_hop_size  \\\n",
       "588     0.314969      0.270862                       25  ...               5   \n",
       "589     0.316552      0.368517                       19  ...               7   \n",
       "590     0.314969      0.270862                       25  ...               5   \n",
       "591     0.314961      0.200846                       29  ...               4   \n",
       "592     0.318118      0.450105                       21  ...               7   \n",
       "593     0.314961      0.200846                       29  ...               4   \n",
       "594     0.316536      0.218849                       23  ...               5   \n",
       "595     0.316528      0.121933                       29  ...               4   \n",
       "596     0.314953      0.054409                       37  ...               3   \n",
       "597     0.319693      0.607014                       17  ...               8   \n",
       "\n",
       "     reach_ratio  centrality_product  centrality_sum  centrality_ratio_1  \\\n",
       "588            8                 0.8             0.5            0.000000   \n",
       "589           10                 1.0             0.7            0.555556   \n",
       "590            8                 0.8             0.5            0.000000   \n",
       "591            7                 0.7             0.4            0.000000   \n",
       "592            8                 0.8             0.7            0.733796   \n",
       "593            7                 0.7             0.4            0.000000   \n",
       "594            8                 0.8             0.5            0.388889   \n",
       "595            5                 0.5             0.4            0.196708   \n",
       "596            4                 0.4             0.3            0.000000   \n",
       "597            9                 0.9             0.8            2.027778   \n",
       "\n",
       "     centrality_ratio_2  edge_connectivity_impact  flow_concentration  root  \\\n",
       "588            4.061111                    0.0000           67.425966     5   \n",
       "589            5.722222                    2.2500           47.706939     5   \n",
       "590            4.061111                    0.0000           67.425966     5   \n",
       "591            3.727778                    0.0000           59.327327     5   \n",
       "592            6.033333                    1.2500           32.569364     5   \n",
       "593            3.727778                    0.0000           59.327327     5   \n",
       "594            5.111111                    1.7500           41.374339     5   \n",
       "595            4.427778                    1.0000           34.395413     5   \n",
       "596            3.127778                    0.0000           46.973874     5   \n",
       "597            7.277778                    1.6875           29.661141     5   \n",
       "\n",
       "     is_root  \n",
       "588        0  \n",
       "589        0  \n",
       "590        0  \n",
       "591        0  \n",
       "592        1  \n",
       "593        0  \n",
       "594        0  \n",
       "595        0  \n",
       "596        0  \n",
       "597        0  \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocess(df)\n",
    "\n",
    "# check with project guideline\n",
    "df[(df['language'] == 'Arabic') & (df['sentence'] == 62)]\n",
    "\n",
    "#n number of nodes, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa75b83b-286a-43af-bce7-ad75a1240537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check columns where all values are 0\n",
    "df.columns[(df == 0).all()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52580dd1-8287-4ec8-a2e5-05ce6fe294cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop root column\n",
    "df = df.drop('root', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907983e9-8c76-4114-b441-4010049d8979",
   "metadata": {},
   "source": [
    "## Data Exploration of the Expanded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f834b-fdc6-4d43-878b-d1ea21e330b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save expanded data\n",
    "df.to_csv('../outputs/binary_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1aed7-5791-4750-9003-d51cb240a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../outputs/binary_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2bbc8ee-fcac-442a-b50b-3a5fbc89644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 197479 entries, 0 to 197478\n",
      "Data columns (total 33 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   language                  197479 non-null  object \n",
      " 1   sentence                  197479 non-null  int64  \n",
      " 2   n                         197479 non-null  int64  \n",
      " 3   vertex                    197479 non-null  int64  \n",
      " 4   degree                    197479 non-null  float64\n",
      " 5   betweenness               197479 non-null  float64\n",
      " 6   katz                      197479 non-null  float64\n",
      " 7   eigenvector               197479 non-null  float64\n",
      " 8   sum_distance              197479 non-null  float64\n",
      " 9   distance_from_periphery   197479 non-null  int64  \n",
      " 10  subtree_size              197479 non-null  int64  \n",
      " 11  neighbor_degrees          197479 non-null  int64  \n",
      " 12  neighbor_centralities     197479 non-null  float64\n",
      " 13  second_order_neighbors    197479 non-null  float64\n",
      " 14  relative_centrality       197479 non-null  int64  \n",
      " 15  depth_from_proxy          197479 non-null  float64\n",
      " 16  bridge_count              197479 non-null  int64  \n",
      " 17  local_degree_variance     197479 non-null  int64  \n",
      " 18  median_distance           197479 non-null  float64\n",
      " 19  distance_std              197479 non-null  float64\n",
      " 20  distance_range            197479 non-null  float64\n",
      " 21  subtree_balance           197479 non-null  int64  \n",
      " 22  subtree_count             197479 non-null  float64\n",
      " 23  two_hop_size              197479 non-null  int64  \n",
      " 24  three_hop_size            197479 non-null  int64  \n",
      " 25  reach_ratio               197479 non-null  int64  \n",
      " 26  centrality_product        197479 non-null  float64\n",
      " 27  centrality_sum            197479 non-null  float64\n",
      " 28  centrality_ratio_1        197479 non-null  float64\n",
      " 29  centrality_ratio_2        197479 non-null  float64\n",
      " 30  edge_connectivity_impact  197479 non-null  float64\n",
      " 31  flow_concentration        197479 non-null  float64\n",
      " 32  is_root                   197479 non-null  int64  \n",
      "dtypes: float64(18), int64(14), object(1)\n",
      "memory usage: 49.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fead61b-abc6-43b1-b9fd-5bc49f961094",
   "metadata": {},
   "source": [
    "- change language to categorical variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a95f1dd-a720-4c80-8aff-8f3be650db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['language'] = train_df['language'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee3ce287-716d-4da1-8187-182a5cb3cd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197479, 33)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of rows and columns\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f41346f1-ad39-4645-bde2-ee96980c45f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language                    0\n",
       "sentence                    0\n",
       "n                           0\n",
       "vertex                      0\n",
       "degree                      0\n",
       "betweenness                 0\n",
       "katz                        0\n",
       "eigenvector                 0\n",
       "sum_distance                0\n",
       "distance_from_periphery     0\n",
       "subtree_size                0\n",
       "neighbor_degrees            0\n",
       "neighbor_centralities       0\n",
       "second_order_neighbors      0\n",
       "relative_centrality         0\n",
       "depth_from_proxy            0\n",
       "bridge_count                0\n",
       "local_degree_variance       0\n",
       "median_distance             0\n",
       "distance_std                0\n",
       "distance_range              0\n",
       "subtree_balance             0\n",
       "subtree_count               0\n",
       "two_hop_size                0\n",
       "three_hop_size              0\n",
       "reach_ratio                 0\n",
       "centrality_product          0\n",
       "centrality_sum              0\n",
       "centrality_ratio_1          0\n",
       "centrality_ratio_2          0\n",
       "edge_connectivity_impact    0\n",
       "flow_concentration          0\n",
       "is_root                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm there are no missing values\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8d5c5a1-730c-4866-b1f5-e190b4940ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78be8203-1628-4e06-b60a-6e0574d39b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>n</th>\n",
       "      <th>vertex</th>\n",
       "      <th>degree</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>katz</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>sum_distance</th>\n",
       "      <th>distance_from_periphery</th>\n",
       "      <th>subtree_size</th>\n",
       "      <th>...</th>\n",
       "      <th>two_hop_size</th>\n",
       "      <th>three_hop_size</th>\n",
       "      <th>reach_ratio</th>\n",
       "      <th>centrality_product</th>\n",
       "      <th>centrality_sum</th>\n",
       "      <th>centrality_ratio_1</th>\n",
       "      <th>centrality_ratio_2</th>\n",
       "      <th>edge_connectivity_impact</th>\n",
       "      <th>flow_concentration</th>\n",
       "      <th>is_root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "      <td>197479.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>499.636584</td>\n",
       "      <td>22.374151</td>\n",
       "      <td>11.687076</td>\n",
       "      <td>0.106340</td>\n",
       "      <td>0.187322</td>\n",
       "      <td>0.245772</td>\n",
       "      <td>0.225162</td>\n",
       "      <td>0.181116</td>\n",
       "      <td>107.271467</td>\n",
       "      <td>3.389393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.893660</td>\n",
       "      <td>5.555553</td>\n",
       "      <td>8.563336</td>\n",
       "      <td>0.435071</td>\n",
       "      <td>0.287929</td>\n",
       "      <td>0.228742</td>\n",
       "      <td>6.884631</td>\n",
       "      <td>1.452212</td>\n",
       "      <td>179.944051</td>\n",
       "      <td>0.053170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>291.353683</td>\n",
       "      <td>8.959233</td>\n",
       "      <td>8.269808</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.217725</td>\n",
       "      <td>0.088976</td>\n",
       "      <td>0.049724</td>\n",
       "      <td>0.142715</td>\n",
       "      <td>78.692228</td>\n",
       "      <td>2.585781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984688</td>\n",
       "      <td>2.110591</td>\n",
       "      <td>3.281386</td>\n",
       "      <td>0.206204</td>\n",
       "      <td>0.155349</td>\n",
       "      <td>0.393806</td>\n",
       "      <td>2.166465</td>\n",
       "      <td>1.729120</td>\n",
       "      <td>132.150333</td>\n",
       "      <td>0.224373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062864</td>\n",
       "      <td>0.118939</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.111117</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>238.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.191554</td>\n",
       "      <td>0.066948</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.317042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.391119</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>491.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.105105</td>\n",
       "      <td>0.230216</td>\n",
       "      <td>0.217238</td>\n",
       "      <td>0.148881</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.061810</td>\n",
       "      <td>6.600397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>146.196940</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>736.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.250142</td>\n",
       "      <td>0.258312</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>8.144836</td>\n",
       "      <td>2.393939</td>\n",
       "      <td>230.397901</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>995.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579260</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.878926</td>\n",
       "      <td>17.411765</td>\n",
       "      <td>1581.350990</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentence              n         vertex         degree  \\\n",
       "count  197479.000000  197479.000000  197479.000000  197479.000000   \n",
       "mean      499.636584      22.374151      11.687076       0.106340   \n",
       "std       291.353683       8.959233       8.269808       0.078688   \n",
       "min         2.000000       3.000000       1.000000       0.014493   \n",
       "25%       238.000000      16.000000       5.000000       0.052632   \n",
       "50%       491.000000      21.000000      10.000000       0.083333   \n",
       "75%       736.000000      27.000000      16.000000       0.133333   \n",
       "max       995.000000      70.000000      70.000000       1.000000   \n",
       "\n",
       "         betweenness           katz    eigenvector   sum_distance  \\\n",
       "count  197479.000000  197479.000000  197479.000000  197479.000000   \n",
       "mean        0.187322       0.245772       0.225162       0.181116   \n",
       "std         0.217725       0.088976       0.049724       0.142715   \n",
       "min         0.000000       0.062864       0.118939       0.000001   \n",
       "25%         0.000000       0.183673       0.191554       0.066948   \n",
       "50%         0.105105       0.230216       0.217238       0.148881   \n",
       "75%         0.341667       0.290000       0.250142       0.258312   \n",
       "max         1.000000       1.000000       0.579260       0.707107   \n",
       "\n",
       "       distance_from_periphery   subtree_size  ...   two_hop_size  \\\n",
       "count            197479.000000  197479.000000  ...  197479.000000   \n",
       "mean                107.271467       3.389393  ...       1.893660   \n",
       "std                  78.692228       2.585781  ...       0.984688   \n",
       "min                   2.000000       0.000000  ...       1.000000   \n",
       "25%                  54.000000       1.000000  ...       1.000000   \n",
       "50%                  88.000000       3.000000  ...       2.000000   \n",
       "75%                 137.000000       5.000000  ...       2.000000   \n",
       "max                1094.000000      20.000000  ...       9.000000   \n",
       "\n",
       "       three_hop_size    reach_ratio  centrality_product  centrality_sum  \\\n",
       "count   197479.000000  197479.000000       197479.000000   197479.000000   \n",
       "mean         5.555553       8.563336            0.435071        0.287929   \n",
       "std          2.110591       3.281386            0.206204        0.155349   \n",
       "min          3.000000       3.000000            0.057143        0.042857   \n",
       "25%          4.000000       6.000000            0.275862        0.175000   \n",
       "50%          5.000000       8.000000            0.400000        0.250000   \n",
       "75%          7.000000      10.000000            0.562500        0.363636   \n",
       "max         21.000000      33.000000            1.000000        1.000000   \n",
       "\n",
       "       centrality_ratio_1  centrality_ratio_2  edge_connectivity_impact  \\\n",
       "count       197479.000000       197479.000000             197479.000000   \n",
       "mean             0.228742            6.884631                  1.452212   \n",
       "std              0.393806            2.166465                  1.729120   \n",
       "min              0.000000            2.000000                  0.000000   \n",
       "25%              0.000000            5.317042                  0.000000   \n",
       "50%              0.061810            6.600397                  1.000000   \n",
       "75%              0.295238            8.144836                  2.393939   \n",
       "max              5.000000           20.878926                 17.411765   \n",
       "\n",
       "       flow_concentration        is_root  \n",
       "count       197479.000000  197479.000000  \n",
       "mean           179.944051       0.053170  \n",
       "std            132.150333       0.224373  \n",
       "min              4.111117       0.000000  \n",
       "25%             90.391119       0.000000  \n",
       "50%            146.196940       0.000000  \n",
       "75%            230.397901       0.000000  \n",
       "max           1581.350990       1.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8e104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             n  vertex  degree  betweenness  katz  \\\n",
      "n                         1.00    0.54   -0.54        -0.12 -0.63   \n",
      "vertex                    0.54    1.00   -0.29        -0.07 -0.34   \n",
      "degree                   -0.54   -0.29    1.00         0.70  0.81   \n",
      "betweenness              -0.12   -0.07    0.70         1.00  0.57   \n",
      "katz                     -0.63   -0.34    0.81         0.57  1.00   \n",
      "eigenvector              -0.90   -0.49    0.66         0.15  0.72   \n",
      "sum_distance             -0.35   -0.19    0.73         0.74  0.78   \n",
      "distance_from_periphery   0.90    0.49   -0.53        -0.28 -0.71   \n",
      "subtree_size              0.45    0.24   -0.23         0.07 -0.11   \n",
      "neighbor_degrees          0.92    0.50   -0.66        -0.46 -0.73   \n",
      "neighbor_centralities     0.08    0.04   -0.35        -0.24  0.06   \n",
      "second_order_neighbors   -0.64   -0.35    0.30        -0.06  0.61   \n",
      "relative_centrality       0.13    0.07    0.15         0.52  0.37   \n",
      "depth_from_proxy         -0.15   -0.08    0.75         0.83  0.45   \n",
      "bridge_count              0.34    0.19   -0.38        -0.34 -0.60   \n",
      "local_degree_variance     0.04    0.02    0.64         0.82  0.38   \n",
      "median_distance           0.05    0.03    0.19         0.24  0.22   \n",
      "distance_std              0.64    0.35   -0.61        -0.50 -0.85   \n",
      "distance_range            0.58    0.31   -0.47        -0.34 -0.82   \n",
      "subtree_balance           0.71    0.39   -0.56        -0.36 -0.85   \n",
      "subtree_count            -0.13   -0.07   -0.40        -0.46 -0.10   \n",
      "two_hop_size              0.04    0.02    0.64         0.82  0.38   \n",
      "three_hop_size            0.11    0.06    0.40         0.75  0.44   \n",
      "reach_ratio               0.20    0.11    0.21         0.62  0.38   \n",
      "centrality_product       -0.63   -0.34    0.75         0.59  0.94   \n",
      "centrality_sum           -0.64   -0.35    0.86         0.64  0.93   \n",
      "centrality_ratio_1       -0.17   -0.09    0.77         0.86  0.63   \n",
      "centrality_ratio_2        0.63    0.34    0.04         0.55  0.02   \n",
      "edge_connectivity_impact  0.22    0.12    0.24         0.79  0.19   \n",
      "flow_concentration        0.85    0.46   -0.59        -0.30 -0.49   \n",
      "is_root                  -0.09   -0.05    0.29         0.29  0.24   \n",
      "\n",
      "                          eigenvector  sum_distance  distance_from_periphery  \\\n",
      "n                               -0.90         -0.35                     0.90   \n",
      "vertex                          -0.49         -0.19                     0.49   \n",
      "degree                           0.66          0.73                    -0.53   \n",
      "betweenness                      0.15          0.74                    -0.28   \n",
      "katz                             0.72          0.78                    -0.71   \n",
      "eigenvector                      1.00          0.40                    -0.75   \n",
      "sum_distance                     0.40          1.00                    -0.49   \n",
      "distance_from_periphery         -0.75         -0.49                     1.00   \n",
      "subtree_size                    -0.42          0.07                     0.27   \n",
      "neighbor_degrees                -0.83         -0.56                     0.91   \n",
      "neighbor_centralities           -0.11          0.07                    -0.03   \n",
      "second_order_neighbors           0.76          0.33                    -0.56   \n",
      "relative_centrality             -0.15          0.58                    -0.13   \n",
      "depth_from_proxy                 0.19          0.69                    -0.24   \n",
      "bridge_count                    -0.33         -0.64                     0.54   \n",
      "local_degree_variance           -0.03          0.63                    -0.13   \n",
      "median_distance                 -0.06          0.33                    -0.09   \n",
      "distance_std                    -0.62         -0.73                     0.84   \n",
      "distance_range                  -0.55         -0.53                     0.79   \n",
      "subtree_balance                 -0.68         -0.56                     0.87   \n",
      "subtree_count                    0.13         -0.26                    -0.02   \n",
      "two_hop_size                    -0.03          0.63                    -0.13   \n",
      "three_hop_size                  -0.12          0.71                    -0.15   \n",
      "reach_ratio                     -0.23          0.61                    -0.13   \n",
      "centrality_product               0.70          0.81                    -0.71   \n",
      "centrality_sum                   0.74          0.81                    -0.66   \n",
      "centrality_ratio_1               0.21          0.78                    -0.29   \n",
      "centrality_ratio_2              -0.60          0.35                     0.30   \n",
      "edge_connectivity_impact        -0.19          0.39                     0.01   \n",
      "flow_concentration              -0.73         -0.34                     0.74   \n",
      "is_root                          0.12          0.28                    -0.12   \n",
      "\n",
      "                          subtree_size  neighbor_degrees  ...  two_hop_size  \\\n",
      "n                                 0.45              0.92  ...          0.04   \n",
      "vertex                            0.24              0.50  ...          0.02   \n",
      "degree                           -0.23             -0.66  ...          0.64   \n",
      "betweenness                       0.07             -0.46  ...          0.82   \n",
      "katz                             -0.11             -0.73  ...          0.38   \n",
      "eigenvector                      -0.42             -0.83  ...         -0.03   \n",
      "sum_distance                      0.07             -0.56  ...          0.63   \n",
      "distance_from_periphery           0.27              0.91  ...         -0.13   \n",
      "subtree_size                      1.00              0.36  ...          0.04   \n",
      "neighbor_degrees                  0.36              1.00  ...         -0.24   \n",
      "neighbor_centralities             0.20              0.13  ...         -0.40   \n",
      "second_order_neighbors           -0.22             -0.55  ...         -0.28   \n",
      "relative_centrality               0.21             -0.10  ...          0.43   \n",
      "depth_from_proxy                 -0.02             -0.40  ...          0.90   \n",
      "bridge_count                     -0.11              0.43  ...         -0.26   \n",
      "local_degree_variance             0.04             -0.24  ...          1.00   \n",
      "median_distance                   0.05             -0.03  ...          0.36   \n",
      "distance_std                      0.03              0.75  ...         -0.33   \n",
      "distance_range                   -0.01              0.64  ...         -0.16   \n",
      "subtree_balance                   0.10              0.76  ...         -0.19   \n",
      "subtree_count                     0.03              0.01  ...         -0.77   \n",
      "two_hop_size                      0.04             -0.24  ...          1.00   \n",
      "three_hop_size                    0.17             -0.18  ...          0.77   \n",
      "reach_ratio                       0.29             -0.07  ...          0.61   \n",
      "centrality_product               -0.14             -0.75  ...          0.40   \n",
      "centrality_sum                   -0.21             -0.76  ...          0.47   \n",
      "centrality_ratio_1                0.01             -0.44  ...          0.82   \n",
      "centrality_ratio_2                0.44              0.34  ...          0.67   \n",
      "edge_connectivity_impact          0.22             -0.14  ...          0.59   \n",
      "flow_concentration                0.49              0.86  ...         -0.28   \n",
      "is_root                          -0.01             -0.18  ...          0.26   \n",
      "\n",
      "                          three_hop_size  reach_ratio  centrality_product  \\\n",
      "n                                   0.11         0.20               -0.63   \n",
      "vertex                              0.06         0.11               -0.34   \n",
      "degree                              0.40         0.21                0.75   \n",
      "betweenness                         0.75         0.62                0.59   \n",
      "katz                                0.44         0.38                0.94   \n",
      "eigenvector                        -0.12        -0.23                0.70   \n",
      "sum_distance                        0.71         0.61                0.81   \n",
      "distance_from_periphery            -0.15        -0.13               -0.71   \n",
      "subtree_size                        0.17         0.29               -0.14   \n",
      "neighbor_degrees                   -0.18        -0.07               -0.75   \n",
      "neighbor_centralities               0.21         0.30                0.13   \n",
      "second_order_neighbors             -0.01        -0.05                0.63   \n",
      "relative_centrality                 0.91         0.85                0.47   \n",
      "depth_from_proxy                    0.63         0.44                0.48   \n",
      "bridge_count                       -0.41        -0.45               -0.59   \n",
      "local_degree_variance               0.77         0.61                0.40   \n",
      "median_distance                     0.51         0.47                0.27   \n",
      "distance_std                       -0.45        -0.46               -0.85   \n",
      "distance_range                     -0.27        -0.33               -0.73   \n",
      "subtree_balance                    -0.26        -0.28               -0.78   \n",
      "subtree_count                      -0.50        -0.37               -0.15   \n",
      "two_hop_size                        0.77         0.61                0.40   \n",
      "three_hop_size                      1.00         0.88                0.52   \n",
      "reach_ratio                         0.88         1.00                0.50   \n",
      "centrality_product                  0.52         0.50                1.00   \n",
      "centrality_sum                      0.53         0.35                0.93   \n",
      "centrality_ratio_1                  0.69         0.53                0.60   \n",
      "centrality_ratio_2                  0.78         0.82                0.05   \n",
      "edge_connectivity_impact            0.66         0.63                0.25   \n",
      "flow_concentration                 -0.04         0.13               -0.53   \n",
      "is_root                             0.22         0.16                0.23   \n",
      "\n",
      "                          centrality_sum  centrality_ratio_1  \\\n",
      "n                                  -0.64               -0.17   \n",
      "vertex                             -0.35               -0.09   \n",
      "degree                              0.86                0.77   \n",
      "betweenness                         0.64                0.86   \n",
      "katz                                0.93                0.63   \n",
      "eigenvector                         0.74                0.21   \n",
      "sum_distance                        0.81                0.78   \n",
      "distance_from_periphery            -0.66               -0.29   \n",
      "subtree_size                       -0.21                0.01   \n",
      "neighbor_degrees                   -0.76               -0.44   \n",
      "neighbor_centralities               0.05               -0.23   \n",
      "second_order_neighbors              0.63               -0.02   \n",
      "relative_centrality                 0.45                0.44   \n",
      "depth_from_proxy                    0.57                0.77   \n",
      "bridge_count                       -0.52               -0.36   \n",
      "local_degree_variance               0.47                0.82   \n",
      "median_distance                     0.27                0.19   \n",
      "distance_std                       -0.77               -0.48   \n",
      "distance_range                     -0.63               -0.36   \n",
      "subtree_balance                    -0.71               -0.38   \n",
      "subtree_count                      -0.20               -0.34   \n",
      "two_hop_size                        0.47                0.82   \n",
      "three_hop_size                      0.53                0.69   \n",
      "reach_ratio                         0.35                0.53   \n",
      "centrality_product                  0.93                0.60   \n",
      "centrality_sum                      1.00                0.67   \n",
      "centrality_ratio_1                  0.67                1.00   \n",
      "centrality_ratio_2                  0.01                0.47   \n",
      "edge_connectivity_impact            0.24                0.47   \n",
      "flow_concentration                 -0.58               -0.30   \n",
      "is_root                             0.26                0.32   \n",
      "\n",
      "                          centrality_ratio_2  edge_connectivity_impact  \\\n",
      "n                                       0.63                      0.22   \n",
      "vertex                                  0.34                      0.12   \n",
      "degree                                  0.04                      0.24   \n",
      "betweenness                             0.55                      0.79   \n",
      "katz                                    0.02                      0.19   \n",
      "eigenvector                            -0.60                     -0.19   \n",
      "sum_distance                            0.35                      0.39   \n",
      "distance_from_periphery                 0.30                      0.01   \n",
      "subtree_size                            0.44                      0.22   \n",
      "neighbor_degrees                        0.34                     -0.14   \n",
      "neighbor_centralities                   0.07                     -0.11   \n",
      "second_order_neighbors                 -0.46                     -0.23   \n",
      "relative_centrality                     0.66                      0.54   \n",
      "depth_from_proxy                        0.45                      0.55   \n",
      "bridge_count                           -0.19                     -0.16   \n",
      "local_degree_variance                   0.67                      0.59   \n",
      "median_distance                         0.38                      0.23   \n",
      "distance_std                           -0.08                     -0.23   \n",
      "distance_range                         -0.00                     -0.09   \n",
      "subtree_balance                         0.10                     -0.08   \n",
      "subtree_count                          -0.51                     -0.43   \n",
      "two_hop_size                            0.67                      0.59   \n",
      "three_hop_size                          0.78                      0.66   \n",
      "reach_ratio                             0.82                      0.63   \n",
      "centrality_product                      0.05                      0.25   \n",
      "centrality_sum                          0.01                      0.24   \n",
      "centrality_ratio_1                      0.47                      0.47   \n",
      "centrality_ratio_2                      1.00                      0.67   \n",
      "edge_connectivity_impact                0.67                      1.00   \n",
      "flow_concentration                      0.43                     -0.01   \n",
      "is_root                                 0.12                      0.15   \n",
      "\n",
      "                          flow_concentration  is_root  \n",
      "n                                       0.85    -0.09  \n",
      "vertex                                  0.46    -0.05  \n",
      "degree                                 -0.59     0.29  \n",
      "betweenness                            -0.30     0.29  \n",
      "katz                                   -0.49     0.24  \n",
      "eigenvector                            -0.73     0.12  \n",
      "sum_distance                           -0.34     0.28  \n",
      "distance_from_periphery                 0.74    -0.12  \n",
      "subtree_size                            0.49    -0.01  \n",
      "neighbor_degrees                        0.86    -0.18  \n",
      "neighbor_centralities                   0.40    -0.08  \n",
      "second_order_neighbors                 -0.35     0.03  \n",
      "relative_centrality                     0.13     0.15  \n",
      "depth_from_proxy                       -0.42     0.27  \n",
      "bridge_count                            0.20    -0.17  \n",
      "local_degree_variance                  -0.28     0.26  \n",
      "median_distance                        -0.07     0.06  \n",
      "distance_std                            0.48    -0.19  \n",
      "distance_range                          0.37    -0.14  \n",
      "subtree_balance                         0.52    -0.15  \n",
      "subtree_count                           0.25    -0.11  \n",
      "two_hop_size                           -0.28     0.26  \n",
      "three_hop_size                         -0.04     0.22  \n",
      "reach_ratio                             0.13     0.16  \n",
      "centrality_product                     -0.53     0.23  \n",
      "centrality_sum                         -0.58     0.26  \n",
      "centrality_ratio_1                     -0.30     0.32  \n",
      "centrality_ratio_2                      0.43     0.12  \n",
      "edge_connectivity_impact               -0.01     0.15  \n",
      "flow_concentration                      1.00    -0.12  \n",
      "is_root                                -0.12     1.00  \n",
      "\n",
      "[31 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop non-numeric columns\n",
    "correlation_matrix = df.drop(['sentence', 'language'], axis=1).corr()\n",
    "\n",
    "# Display as table\n",
    "print(correlation_matrix.round(2))\n",
    "correlation_matrix.round(2).to_csv(\"../outputs/correlation_matrix.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b861809-405e-4495-ba49-3975cd4a8457",
   "metadata": {},
   "source": [
    "## Resampling: Splitting Data into Train and Validation Set\n",
    "\n",
    "To estimate the generalization error, we split the data into train and validation set. We will then use a 5-fold cross validation over the train set so we train over a good sample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0f556cb-6554-42e1-9b78-979c90cb115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target value\n",
    "X = train_df.drop('is_root', axis=1)\n",
    "y = train_df['is_root']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1019597-a683-4cba-ae9e-14c34fb97b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grouping by sentence ID\n",
    "groups = train_df['sentence'] \n",
    "\n",
    "# Perform group split (80% train, 20% val)\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "# Verify no sentence appears in both splits\n",
    "train_sentences = set(groups.iloc[train_idx])\n",
    "val_sentences = set(groups.iloc[val_idx])\n",
    "assert train_sentences.isdisjoint(val_sentences), \"Data leakage detected!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4635792-f49e-401b-8694-5288a67ed549",
   "metadata": {},
   "source": [
    "## Per Sentence Normalization\n",
    "\n",
    "It will be better to normalize the data since it has different different ranges. we have to do a sentence level normalization because different sentences have different number of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4367a9f4-e3f7-4ef0-98df-970529d47819",
   "metadata": {},
   "source": [
    "Note: Group by language then sentence coz per sentence will scale all the sentences from all the languages as one. however for example, Arabic and Turkish trees for the same sentence may have different structures, so we Normalize per-language AND per-sentence by grouping by both language and sentence. treating them as a single group would mix languages during normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d201439-eb09-4d06-acf4-c5edb75491b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = X_train.drop(['language', 'sentence', 'n', 'vertex'], axis=1).columns\n",
    "\n",
    "def scaling(X):\n",
    "    \"\"\"\n",
    "    Normalize features using MinMaxScaler\n",
    "    \"\"\"\n",
    "    normalized_ft = X.groupby(['language','sentence'])[features].transform(lambda x: MinMaxScaler().fit_transform(x.values.reshape(-1,1)).flatten())\n",
    "    X_ft= X.drop(features, axis=1) \n",
    "    normalized_X = pd.concat([X_ft, normalized_ft], axis=1)\n",
    "    \n",
    "    return normalized_X\n",
    "\n",
    "X_train_normalized = scaling(X_train)\n",
    "X_val_normalized = scaling(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8a243-fb7c-4659-bfe0-6c2665579c41",
   "metadata": {},
   "source": [
    "we fit and transform the test set independently because the sentences are different in the two sets, so we can't use the scalers used for train to transform the test set, as we performed a within sentence normalization\n",
    "\n",
    "We also only performed normalization on the centrality metrics and on the number of nodes n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bb5f7b1-49a0-4004-a0cc-f7340a1d577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns not useful\n",
    "X_train_normalized = X_train_normalized.drop(['language', 'sentence', 'vertex'], axis=1)\n",
    "X_val_normalized = X_val_normalized.drop(['language', 'sentence', 'vertex'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eef8c8",
   "metadata": {},
   "source": [
    "# Imbalance Handling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023ebc4",
   "metadata": {},
   "source": [
    "We tried undersmapling and oversampling the data but it was not as helpful, so it will remain commented here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e09884",
   "metadata": {},
   "source": [
    "## Undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57ac3bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport ast\\nimport networkx as nx\\nfrom tqdm import tqdm\\n\\n# Function to remove bottom 25% nodes by degree\\ndef prune_low_degree_nodes(edgelist_str, retain_percent=0.75):\\n    edges = ast.literal_eval(edgelist_str)\\n    G = nx.Graph(edges)\\n\\n    if len(G.nodes) == 0:\\n        return edges  # nothing to do\\n\\n    # Sort nodes by degree\\n    degrees = dict(G.degree())\\n    sorted_nodes = sorted(degrees.items(), key=lambda x: x[1])\\n\\n    # Keep top N% nodes\\n    keep_n = int(len(sorted_nodes) * retain_percent)\\n    keep_nodes = set([node for node, _ in sorted_nodes[-keep_n:]])\\n\\n    # Filter edges\\n    pruned_edges = [(u, v) for u, v in edges if u in keep_nodes and v in keep_nodes]\\n\\n    return pruned_edges\\n\\ntqdm.pandas()\\nX_train_normalized = X_train_normalized.copy()\\nX_train_normalized['edgelist'] = X_train_normalized.progress_apply(\\n    lambda row: prune_low_degree_nodes(row['edgelist']) if row['language'] == major_class else row['edgelist'],\\n    axis=1\\n)\\n)\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import ast\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to remove bottom 25% nodes by degree\n",
    "def prune_low_degree_nodes(edgelist_str, retain_percent=0.75):\n",
    "    edges = ast.literal_eval(edgelist_str)\n",
    "    G = nx.Graph(edges)\n",
    "\n",
    "    if len(G.nodes) == 0:\n",
    "        return edges  # nothing to do\n",
    "\n",
    "    # Sort nodes by degree\n",
    "    degrees = dict(G.degree())\n",
    "    sorted_nodes = sorted(degrees.items(), key=lambda x: x[1])\n",
    "    \n",
    "    # Keep top N% nodes\n",
    "    keep_n = int(len(sorted_nodes) * retain_percent)\n",
    "    keep_nodes = set([node for node, _ in sorted_nodes[-keep_n:]])\n",
    "    \n",
    "    # Filter edges\n",
    "    pruned_edges = [(u, v) for u, v in edges if u in keep_nodes and v in keep_nodes]\n",
    "    \n",
    "    return pruned_edges\n",
    "\n",
    "tqdm.pandas()\n",
    "X_train_normalized = X_train_normalized.copy()\n",
    "X_train_normalized['edgelist'] = X_train_normalized.progress_apply(\n",
    "    lambda row: prune_low_degree_nodes(row['edgelist']) if row['language'] == major_class else row['edgelist'],\n",
    "    axis=1\n",
    ")\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf2faa",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c13695ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom imblearn.over_sampling import RandomOverSampler\\nimport pandas as pd\\n\\n# Step 1: Separate features and target\\nX_features = X_train_normalized.drop(columns=['target', 'language', 'sentence', 'node', 'group'])  # Keep only numerical features\\ny_target = train_df['target']\\n\\n# Save identifier columns for later merge\\nidentifier_cols = train_df[['language', 'sentence', 'node']].reset_index(drop=True)\\n\\n# Step 2: Apply RandomOverSampler to balance the minority class (target == 1)\\nros = RandomOverSampler(sampling_strategy='minority', random_state=42)\\nX_balanced, y_balanced = ros.fit_resample(X_features, y_target)\\n\\n# Step 3: Reattach metadata using sample indices\\nresampled_ids = identifier_cols.iloc[ros.sample_indices_].reset_index(drop=True)\\nresampled_data = pd.concat([\\n    resampled_ids,\\n    pd.DataFrame(X_balanced, columns=X_features.columns),\\n    pd.Series(y_balanced, name='target')\\n], axis=1)\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Separate features and target\n",
    "X_features = X_train_normalized.drop(columns=['target', 'language', 'sentence', 'node', 'group'])  # Keep only numerical features\n",
    "y_target = train_df['target']\n",
    "\n",
    "# Save identifier columns for later merge\n",
    "identifier_cols = train_df[['language', 'sentence', 'node']].reset_index(drop=True)\n",
    "\n",
    "# Step 2: Apply RandomOverSampler to balance the minority class (target == 1)\n",
    "ros = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "X_balanced, y_balanced = ros.fit_resample(X_features, y_target)\n",
    "\n",
    "# Step 3: Reattach metadata using sample indices\n",
    "resampled_ids = identifier_cols.iloc[ros.sample_indices_].reset_index(drop=True)\n",
    "resampled_data = pd.concat([\n",
    "    resampled_ids,\n",
    "    pd.DataFrame(X_balanced, columns=X_features.columns),\n",
    "    pd.Series(y_balanced, name='target')\n",
    "], axis=1)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabeaa27-ff39-4937-9dce-438df8d13a2b",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6355a9-d25d-4fea-8c66-ed5d01d4361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     37903\n",
      "           1       0.28      0.49      0.36      2100\n",
      "\n",
      "    accuracy                           0.91     40003\n",
      "   macro avg       0.63      0.71      0.65     40003\n",
      "weighted avg       0.93      0.91      0.92     40003\n",
      "\n",
      "F1-Score (Root): 0.357\n"
     ]
    }
   ],
   "source": [
    "# Initialize with balanced class weights\n",
    "rf = RandomForestClassifier(\n",
    "      # Key: Auto-adjusts weights for the rare class\n",
    "    random_state=42, n_estimators=200,        # Number of trees\n",
    "    max_depth=100,             # Control overfitting\n",
    "    min_samples_leaf=10, class_weight='balanced_subsample'\n",
    ")\n",
    "# Train\n",
    "rf.fit(X_train_normalized, y_train)\n",
    "y_pred = rf.predict(X_val_normalized)\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Focus on F1-score for the root class\n",
    "print(f\"F1-Score (Root): {f1_score(y_val, y_pred, pos_label=1):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bfa71b5-a600-4257-b284-49d82233cc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': np.float64(0.03847849946459201),\n",
       " 'degree': np.float64(0.016023147099236943),\n",
       " 'betweenness': np.float64(0.08085509024635766),\n",
       " 'katz': np.float64(0.030191497263110198),\n",
       " 'eigenvector': np.float64(0.06611384285600547),\n",
       " 'sum_distance': np.float64(0.04646825668930043),\n",
       " 'distance_from_periphery': np.float64(0.024259343528843923),\n",
       " 'subtree_size': np.float64(0.016431236253600566),\n",
       " 'neighbor_degrees': np.float64(0.06750688593749764),\n",
       " 'neighbor_centralities': np.float64(0.015537459585459499),\n",
       " 'second_order_neighbors': np.float64(0.015419401229067032),\n",
       " 'relative_centrality': np.float64(0.011408245360421582),\n",
       " 'depth_from_proxy': np.float64(0.01960154221627139),\n",
       " 'bridge_count': np.float64(0.0500579467063153),\n",
       " 'local_degree_variance': np.float64(0.027830265753973807),\n",
       " 'median_distance': np.float64(0.013751323308300709),\n",
       " 'distance_std': np.float64(0.015846993470639628),\n",
       " 'distance_range': np.float64(0.0309724274129766),\n",
       " 'subtree_balance': np.float64(0.011852567734967616),\n",
       " 'subtree_count': np.float64(0.03045047654335542),\n",
       " 'two_hop_size': np.float64(0.023158099650506067),\n",
       " 'three_hop_size': np.float64(0.017995933186440924),\n",
       " 'reach_ratio': np.float64(0.017866429613175538),\n",
       " 'centrality_product': np.float64(0.018419455038661214),\n",
       " 'centrality_sum': np.float64(0.024060068619286192),\n",
       " 'centrality_ratio_1': np.float64(0.09402988068384788),\n",
       " 'centrality_ratio_2': np.float64(0.06684885385317983),\n",
       " 'edge_connectivity_impact': np.float64(0.07255668142884171),\n",
       " 'flow_concentration': np.float64(0.03600814926576727)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "dict(zip(X_train_normalized, importances))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c4a17-6622-4ca0-b33e-b095a29c6092",
   "metadata": {},
   "source": [
    "### Linear Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b622746-ebf7-454f-abb4-e657812b73e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "lg_model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1],             # Regularization strength\n",
    "    'penalty': ['l2'],                  \n",
    "    'solver': ['lbfgs', 'liblinear'],                \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lg_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=GroupKFold(n_splits=5),\n",
    "    scoring='f1',   \n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_normalized, y_train, groups=X_train['sentence'])\n",
    "\n",
    "\n",
    "# Train\n",
    "logreg = grid_search.best_estimator_\n",
    "\n",
    "# Predict\n",
    "y_pred = logreg.predict(X_val_normalized)\n",
    "y_probs = logreg.predict_proba(X_val_normalized)[:, 1]  # Probabilities for root class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb60846a-c816-41c4-bf95-3f6a25240806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.74      0.84     37903\n",
      "           1       0.14      0.80      0.25      2100\n",
      "\n",
      "    accuracy                           0.74     40003\n",
      "   macro avg       0.56      0.77      0.54     40003\n",
      "weighted avg       0.94      0.74      0.81     40003\n",
      "\n",
      "Test F1 Score: 0.24507434263531824\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Test F1 Score:\", f1_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca512bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "5 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/discriminant_analysis.py\", line 700, in fit\n",
      "    raise NotImplementedError(\"shrinkage not supported with 'svd' solver.\")\n",
      "NotImplementedError: shrinkage not supported with 'svd' solver.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.29640119 0.2963828         nan 0.29411817]\n",
      "  warnings.warn(\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "param_grid = {\n",
    "    'shrinkage': [None, 'auto'],  \n",
    "    'solver': ['svd', 'lsqr']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lda,\n",
    "    param_grid=param_grid,\n",
    "    cv=GroupKFold(n_splits=5),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_normalized, y_train, groups=X_train['sentence'])\n",
    "\n",
    "# Best model\n",
    "lda_best = grid_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = lda_best.predict(X_val_normalized)\n",
    "y_probs = lda_best.predict_proba(X_val_normalized)[:, 1]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbba3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Hyperparameters: {'shrinkage': None, 'solver': 'svd'}\n",
      "\n",
      " Classification Report (LDA):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9609    0.9665    0.9637     37903\n",
      "           1     0.3243    0.2905    0.3065      2100\n",
      "\n",
      "    accuracy                         0.9310     40003\n",
      "   macro avg     0.6426    0.6285    0.6351     40003\n",
      "weighted avg     0.9275    0.9310    0.9292     40003\n",
      "\n",
      "\n",
      " F1 Score on Validation Set (LDA): 0.3065\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Evaluation for LDA\n",
    "print(\" Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "print(\"\\n Classification Report (LDA):\")\n",
    "print(classification_report(y_val, y_pred, digits=4))\n",
    "\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print(f\"\\n F1 Score on Validation Set (LDA): {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da893b6-57c6-4188-aeb2-c793b5e3a65b",
   "metadata": {},
   "source": [
    "## Non Linear Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020c480-1be4-43d4-a675-44203b5381ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     37903\n",
      "           1       0.21      0.21      0.21      2100\n",
      "\n",
      "    accuracy                           0.92     40003\n",
      "   macro avg       0.58      0.58      0.58     40003\n",
      "weighted avg       0.92      0.92      0.92     40003\n",
      "\n",
      "Test F1 Score: 0.2078233741300696\n"
     ]
    }
   ],
   "source": [
    "# Define KNN model\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Hyperparameter grid for KNN\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 3, 5],\n",
    "    'metric': ['euclidean', 'minkowski', 'manhattan']\n",
    "}\n",
    "\n",
    "# Grid search with GroupKFold\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knn_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=GroupKFold(n_splits=5),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "grid_search.fit(X_train_normalized, y_train, groups=X_train['sentence'])\n",
    "\n",
    "# Best estimator\n",
    "knn = grid_search.best_estimator_\n",
    "\n",
    "# Predict\n",
    "y_pred = knn.predict(X_val_normalized)\n",
    "\n",
    "# Probabilities \n",
    "y_probs = knn.predict_proba(X_val_normalized)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Test F1 Score:\", f1_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a65b5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (MLP): {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'solver': 'adam'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     37903\n",
      "           1       0.59      0.06      0.11      2100\n",
      "\n",
      "    accuracy                           0.95     40003\n",
      "   macro avg       0.77      0.53      0.54     40003\n",
      "weighted avg       0.93      0.95      0.93     40003\n",
      "\n",
      "Test F1 Score (MLP): 0.11211729193617939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp_model = MLPClassifier(random_state=42, max_iter=500)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'solver': ['adam']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=mlp_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=GroupKFold(n_splits=5),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_normalized, y_train, groups=X_train['sentence'])\n",
    "\n",
    "best_mlp = grid_search.best_estimator_\n",
    "y_pred = best_mlp.predict(X_val_normalized)\n",
    "y_probs = best_mlp.predict_proba(X_val_normalized)[:, 1]\n",
    "\n",
    "print(\"Best Parameters (MLP):\", grid_search.best_params_)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Test F1 Score (MLP):\", f1_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e4cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (QDA): {'reg_param': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     37903\n",
      "           1       0.31      0.31      0.31      2100\n",
      "\n",
      "    accuracy                           0.93     40003\n",
      "   macro avg       0.64      0.64      0.64     40003\n",
      "weighted avg       0.93      0.93      0.93     40003\n",
      "\n",
      "Test F1 Score (QDA): 0.3122043519394513\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qda_model = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "param_grid = {\n",
    "    'reg_param': [0.0, 0.1, 0.5]  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=qda_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=GroupKFold(n_splits=5),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_normalized, y_train, groups=X_train['sentence'])\n",
    "\n",
    "best_qda = grid_search.best_estimator_\n",
    "y_pred = best_qda.predict(X_val_normalized)\n",
    "y_probs = best_qda.predict_proba(X_val_normalized)[:, 1]\n",
    "\n",
    "print(\"Best Parameters (QDA):\", grid_search.best_params_)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Test F1 Score (QDA):\", f1_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808c4618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Parameters (GNB): {}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86     37903\n",
      "           1       0.15      0.72      0.25      2100\n",
      "\n",
      "    accuracy                           0.77     40003\n",
      "   macro avg       0.57      0.75      0.56     40003\n",
      "weighted avg       0.94      0.77      0.83     40003\n",
      "\n",
      "Test F1 Score (GNB): 0.24905784040635753\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gnb_model = GaussianNB()\n",
    "\n",
    "# No real hyperparameters to tune in GNB, but wrap for consistency\n",
    "param_grid = {}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gnb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=GroupKFold(n_splits=5),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_normalized, y_train, groups=X_train['sentence'])\n",
    "\n",
    "best_gnb = grid_search.best_estimator_\n",
    "y_pred = best_gnb.predict(X_val_normalized)\n",
    "y_probs = best_gnb.predict_proba(X_val_normalized)[:, 1]\n",
    "\n",
    "print(\"Best Parameters (GNB):\", grid_search.best_params_)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Test F1 Score (GNB):\", f1_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99ddaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters (Decision Tree): {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85     37903\n",
      "           1       0.14      0.75      0.24      2100\n",
      "\n",
      "    accuracy                           0.75     40003\n",
      "   macro avg       0.56      0.75      0.55     40003\n",
      "weighted avg       0.94      0.75      0.82     40003\n",
      "\n",
      "Test F1 Score (Decision Tree): 0.24180390949669078\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dt_model = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=GroupKFold(n_splits=5),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_normalized, y_train, groups=X_train['sentence'])\n",
    "\n",
    "best_dt = grid_search.best_estimator_\n",
    "y_pred = best_dt.predict(X_val_normalized)\n",
    "y_probs = best_dt.predict_proba(X_val_normalized)[:, 1]\n",
    "\n",
    "print(\"Best Parameters (Decision Tree):\", grid_search.best_params_)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Test F1 Score (Decision Tree):\", f1_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5022\n",
      "[LightGBM] [Info] Number of data points in the train set: 125964, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4964\n",
      "[LightGBM] [Info] Number of data points in the train set: 125993, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4951\n",
      "[LightGBM] [Info] Number of data points in the train set: 126006, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5059\n",
      "[LightGBM] [Info] Number of data points in the train set: 125966, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 6720, number of negative: 119255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4923\n",
      "[LightGBM] [Info] Number of data points in the train set: 125975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 8400, number of negative: 149076\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4953\n",
      "[LightGBM] [Info] Number of data points in the train set: 157476, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 50, 'min_child_samples': 20, 'n_estimators': 250, 'num_leaves': 64}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.91     37903\n",
      "           1       0.20      0.65      0.31      2100\n",
      "\n",
      "    accuracy                           0.85     40003\n",
      "   macro avg       0.59      0.75      0.61     40003\n",
      "weighted avg       0.94      0.85      0.88     40003\n",
      "\n",
      "Test F1 Score: 0.3062535211267606\n",
      "Feature Importances: {'n': np.int32(1078), 'degree': np.int32(188), 'betweenness': np.int32(624), 'katz': np.int32(585), 'eigenvector': np.int32(734), 'sum_distance': np.int32(1109), 'distance_from_periphery': np.int32(579), 'subtree_size': np.int32(575), 'neighbor_degrees': np.int32(332), 'neighbor_centralities': np.int32(396), 'second_order_neighbors': np.int32(516), 'relative_centrality': np.int32(323), 'depth_from_proxy': np.int32(2), 'bridge_count': np.int32(877), 'local_degree_variance': np.int32(0), 'median_distance': np.int32(524), 'distance_std': np.int32(504), 'distance_range': np.int32(1096), 'subtree_balance': np.int32(364), 'subtree_count': np.int32(710), 'two_hop_size': np.int32(0), 'three_hop_size': np.int32(349), 'reach_ratio': np.int32(608), 'centrality_product': np.int32(189), 'centrality_sum': np.int32(200), 'centrality_ratio_1': np.int32(588), 'centrality_ratio_2': np.int32(742), 'edge_connectivity_impact': np.int32(758), 'flow_concentration': np.int32(1200)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize LightGBM \n",
    "lgb_model = LGBMClassifier(\n",
    "    class_weight='balanced',  \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Parameter grid for LightGBM\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 250],\n",
    "    'max_depth': [20, 30, 50],\n",
    "    'num_leaves': [31, 64],  \n",
    "    'min_child_samples': [10, 20],  \n",
    "    'learning_rate': [0.05, 0.1]  \n",
    "}\n",
    "\n",
    "# Group-aware GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=GroupKFold(n_splits=5),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit LightGBM model\n",
    "grid_search.fit(\n",
    "    X_train_normalized,\n",
    "    y_train,\n",
    "    groups=X_train['sentence']\n",
    ")\n",
    "\n",
    "# Best model\n",
    "best_lgb = grid_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_lgb.predict(X_val_normalized)\n",
    "y_probs = best_lgb.predict_proba(X_val_normalized)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Test F1 Score:\", f1_score(y_val, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "importances = best_lgb.feature_importances_\n",
    "print(\"Feature Importances:\", dict(zip(X_train_normalized.columns, importances)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081b56a-1ed7-45d0-b398-1184027fd7f9",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b94bba-2fff-48dd-817e-5a0f788a4526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters: {'max_depth': 50, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 250}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     37903\n",
      "           1       0.28      0.49      0.36      2100\n",
      "\n",
      "    accuracy                           0.91     40003\n",
      "   macro avg       0.63      0.71      0.65     40003\n",
      "weighted avg       0.93      0.91      0.92     40003\n",
      "\n",
      "Test F1 Score: 0.3567231247839613\n",
      "Feature Importances: {'n': np.float64(0.03859539947753973), 'degree': np.float64(0.019149373608078283), 'betweenness': np.float64(0.08077164802785343), 'katz': np.float64(0.029696600495518987), 'eigenvector': np.float64(0.06711122174862386), 'sum_distance': np.float64(0.044912338498090724), 'distance_from_periphery': np.float64(0.02433993750733379), 'subtree_size': np.float64(0.01637481551057448), 'neighbor_degrees': np.float64(0.06871553860414298), 'neighbor_centralities': np.float64(0.015382663591974913), 'second_order_neighbors': np.float64(0.01546243505501663), 'relative_centrality': np.float64(0.011359577744306014), 'depth_from_proxy': np.float64(0.018722719200069612), 'bridge_count': np.float64(0.049941172434293274), 'local_degree_variance': np.float64(0.025053864307546074), 'median_distance': np.float64(0.0139370561967763), 'distance_std': np.float64(0.015559023849005541), 'distance_range': np.float64(0.030965636423043712), 'subtree_balance': np.float64(0.011938957231063179), 'subtree_count': np.float64(0.03062677892837068), 'two_hop_size': np.float64(0.020461185289436454), 'three_hop_size': np.float64(0.01879329274572709), 'reach_ratio': np.float64(0.01779520363280799), 'centrality_product': np.float64(0.02015205915841056), 'centrality_sum': np.float64(0.023326187580019163), 'centrality_ratio_1': np.float64(0.09354576751601457), 'centrality_ratio_2': np.float64(0.06699277740684983), 'edge_connectivity_impact': np.float64(0.07423500129308278), 'flow_concentration': np.float64(0.036081766938429294)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Random Forest with balanced class weights\n",
    "rf_model = RandomForestClassifier(\n",
    "    class_weight='balanced_subsample',  \n",
    "    random_state=42,\n",
    "    n_jobs=-1  \n",
    ")\n",
    "\n",
    "# Parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 250],       \n",
    "    'max_depth': [20, 30, 50],        \n",
    "    'min_samples_split': [5, 10],     \n",
    "    'min_samples_leaf': [6, 10],\n",
    "}\n",
    "\n",
    "# Group-aware GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=GroupKFold(n_splits=5),  \n",
    "    scoring='f1',                \n",
    "    n_jobs=-1,                   \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(\n",
    "    X_train_normalized,  \n",
    "    y_train,\n",
    "    groups=X_train['sentence']  \n",
    ")\n",
    "\n",
    "# Best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_rf.predict(X_val_normalized)\n",
    "y_probs = best_rf.predict_proba(X_val_normalized)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Test F1 Score:\", f1_score(y_val, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "importances = best_rf.feature_importances_\n",
    "print(\"Feature Importances:\", dict(zip(X_train_normalized, importances)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b7a89-f54f-4da8-870e-1b1bf3e222da",
   "metadata": {},
   "source": [
    "## Fit the Chosen Model on Entire Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0884d2d-66bb-4d5f-9d18-812f28026879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>degree</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>katz</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>sum_distance</th>\n",
       "      <th>distance_from_periphery</th>\n",
       "      <th>subtree_size</th>\n",
       "      <th>neighbor_degrees</th>\n",
       "      <th>neighbor_centralities</th>\n",
       "      <th>...</th>\n",
       "      <th>subtree_count</th>\n",
       "      <th>two_hop_size</th>\n",
       "      <th>three_hop_size</th>\n",
       "      <th>reach_ratio</th>\n",
       "      <th>centrality_product</th>\n",
       "      <th>centrality_sum</th>\n",
       "      <th>centrality_ratio_1</th>\n",
       "      <th>centrality_ratio_2</th>\n",
       "      <th>edge_connectivity_impact</th>\n",
       "      <th>flow_concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.629551</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.254313</td>\n",
       "      <td>0.22093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n  degree  betweenness      katz  eigenvector  sum_distance  \\\n",
       "0  21     0.0          0.0  0.629551     0.002494      0.254313   \n",
       "\n",
       "   distance_from_periphery  subtree_size  neighbor_degrees  \\\n",
       "0                  0.22093           1.0               1.0   \n",
       "\n",
       "   neighbor_centralities  ...  subtree_count  two_hop_size  three_hop_size  \\\n",
       "0                    1.0  ...            1.0           0.0             0.2   \n",
       "\n",
       "   reach_ratio  centrality_product  centrality_sum  centrality_ratio_1  \\\n",
       "0         0.25                0.25             0.2                 0.0   \n",
       "\n",
       "   centrality_ratio_2  edge_connectivity_impact  flow_concentration  \n",
       "0             0.31693                       0.0                 1.0  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized = scaling(X).drop(['language', 'sentence', 'vertex'], axis=1)\n",
    "X_normalized.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8e67cd6-8bf2-4886-b07a-1b25b7bd8ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=50,\n",
       "                       min_samples_leaf=10, min_samples_split=5,\n",
       "                       n_estimators=250, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=50,\n",
       "                       min_samples_leaf=10, min_samples_split=5,\n",
       "                       n_estimators=250, n_jobs=-1, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', max_depth=50,\n",
       "                       min_samples_leaf=10, min_samples_split=5,\n",
       "                       n_estimators=250, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit whole data\n",
    "best_rf.fit(X_normalized, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f35362-cd91-4e63-aedf-6531568c814e",
   "metadata": {},
   "source": [
    "## Make Predictions on Test Set - Top 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2051014-e9b3-4be6-8bcd-f67c33e2d49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>10391</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10391</th>\n",
       "      <td>10392</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10392</th>\n",
       "      <td>10393</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10393</th>\n",
       "      <td>10394</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10394</th>\n",
       "      <td>10395</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10395 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  root\n",
       "0          1    37\n",
       "1          2    46\n",
       "2          3     2\n",
       "3          4    18\n",
       "4          5     3\n",
       "...      ...   ...\n",
       "10390  10391    13\n",
       "10391  10392     8\n",
       "10392  10393    26\n",
       "10393  10394    20\n",
       "10394  10395    10\n",
       "\n",
       "[10395 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read test data\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "X_test = preprocess(test_df)\n",
    "test_normalized = scaling(X_test).drop(['language', 'sentence', 'vertex'], axis=1)\n",
    "\n",
    "# Predictions\n",
    "test_pred = best_rf.predict(test_normalized)\n",
    "test_probs = best_rf.predict_proba(test_normalized)[:, 1]\n",
    "\n",
    "X_test['probability'] = test_probs\n",
    "\n",
    "df_max = X_test.loc[X_test.groupby(['language', 'sentence'])['probability'].idxmax()]\n",
    "\n",
    "df_max = df_max[['language','sentence', 'vertex']].rename(columns={'vertex': 'root'}).reset_index(drop=True)\n",
    "\n",
    "\n",
    "submission_df = test_df.merge(df_max, on=['language', 'sentence'], how='left')\n",
    "submission_df = submission_df[['id', 'root']]\n",
    "\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f994d",
   "metadata": {},
   "source": [
    "Feature Importance for Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a80c234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get feature importances and names\n",
    "importances = best_rf.feature_importances_\n",
    "feature_names = test_normalized.columns  \n",
    "\n",
    "# DataFrame for better plotting\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))  # Show top 20\n",
    "plt.title('Top Feature Importances (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc22ec-1ce4-4fab-bd8e-3bd5f1dae2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission_randomforest_features_new.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "submission_df.to_csv('../outputfinal_submission.csv.csv', index=False)\n",
    "print(\"Submission file created: final_submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
